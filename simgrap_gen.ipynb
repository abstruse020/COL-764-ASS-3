{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf86ea9-f7ae-4d9e-9ea9-cbc2bac5dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from sknetwork.ranking import PageRank\n",
    "from IPython.display import SVG\n",
    "from sknetwork.visualization import svg_graph\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b99f42-a63c-4520-ab2f-5ccd8f8fe6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vocab_class import TermVocab\n",
    "TVocab = TermVocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6884ba82-8ad1-4680-893f-011a5926d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/harsh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aace6e8c-e3a7-4c4d-bd6b-ff6aee6ee80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_dir = '20news-bydate-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e487c1c5-a06f-45c7-8587-6efc8e18dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class genSimGraph:\n",
    "    def __init__(self, coll_dir, op_file):\n",
    "        self.coll_dir = coll_dir\n",
    "        self.op_file = op_file\n",
    "        self.doc_term_dict = None\n",
    "        self.vocab = TermVocab()\n",
    "        self.limit_file_read_to = 10000\n",
    "        self.file_count = 0\n",
    "        self.docs_list = []\n",
    "    \n",
    "    def cosine_sim(self, d1, d2):\n",
    "        sim = np.dot(d1, d2)/(np.linalg.norm(d1) * np.linalg.norm(d2))\n",
    "        return sim\n",
    "        \n",
    "    def generate_term_set(self):\n",
    "        limit_file_read_to = self.limit_file_read_to\n",
    "        coll_dir = self.coll_dir\n",
    "        doc_term_dict = {}\n",
    "        print('Creating Term set for docs')\n",
    "        ps = PorterStemmer()\n",
    "        docs_list = []\n",
    "        file_count = 0\n",
    "        read_file_count = 0\n",
    "        for foldername in os.listdir(coll_dir):\n",
    "            print('For Folder:', foldername)\n",
    "            path_to_file = os.path.join(coll_dir, foldername)\n",
    "            for filename in os.listdir(path_to_file):\n",
    "                file_count+=1\n",
    "                #print('---------------------For File:', filename)\n",
    "                #print('file:', foldername+'/'+filename,end = ' ')\n",
    "                docs_list.append(foldername+'/'+filename)\n",
    "                with open(os.path.join(path_to_file, filename), 'r', encoding= 'latin') as f:\n",
    "                    content = None\n",
    "                    try:\n",
    "                        content = f.read()\n",
    "                    except:\n",
    "                        print('-------------cant read',foldername +'/'+filename)\n",
    "                        continue\n",
    "                    read_file_count +=1\n",
    "                    #print(content)\n",
    "                    doc_terms = word_tokenize(content)\n",
    "                    #print(doc_terms)\n",
    "                    stemmed_terms = [ps.stem(term) for term in doc_terms]\n",
    "                    #print('non unique',len(stemmed_terms))\n",
    "                    #print('uniq', len(set(stemmed_terms)))\n",
    "                    doc_term_dict[foldername+'/'+filename] = set(stemmed_terms)\n",
    "                    [self.vocab.add_term(term) for term in stemmed_terms]\n",
    "                    #TVocab.add_term(stemmed_terms[0])\n",
    "                    #print(stemmed_terms)\n",
    "                if file_count>=limit_file_read_to:\n",
    "                    break\n",
    "            if file_count>=limit_file_read_to:\n",
    "                break\n",
    "        print('File count:', file_count)\n",
    "        self.file_count = file_count\n",
    "        print('Read File Count:', read_file_count)\n",
    "        self.doc_term_dict = doc_term_dict\n",
    "        self.docs_list = docs_list\n",
    "        return doc_term_dict\n",
    "    \n",
    "    def write_to_file(self, doc1, doc2, sim, path = None):\n",
    "        if path == None:\n",
    "            path = self.op_file\n",
    "        content = \"%s\\t%s\\t%0.4f\\n\"%(doc1, doc2, sim)\n",
    "        with open(path, '+a') as file:\n",
    "            file.write(content)\n",
    "        return True\n",
    "    \n",
    "    def clear_file(self, filename):\n",
    "        open(filename, 'w').close()\n",
    "        return True\n",
    "    \n",
    "    def gen_vocab(self):\n",
    "        limit_file_read_to = self.limit_file_read_to\n",
    "        coll_dir = self.coll_dir\n",
    "        idf = {}\n",
    "        self.vocab = TermVocab()\n",
    "        print('Generating vocab')\n",
    "        ps = PorterStemmer()\n",
    "        file_count = 0\n",
    "        read_file_count = 0\n",
    "        for foldername in os.listdir(coll_dir):\n",
    "            print('For Folder:', foldername)\n",
    "            path_to_file = os.path.join(coll_dir, foldername)\n",
    "            for filename in os.listdir(path_to_file):\n",
    "                file_count+=1\n",
    "                #print('---------------------For File:', filename)\n",
    "                #print('file:', foldername+'/'+filename,end = ' ')\n",
    "                with open(os.path.join(path_to_file, filename), 'r',encoding= 'latin') as f:\n",
    "                    content = None\n",
    "                    try:\n",
    "                        content = f.read()\n",
    "                    except:\n",
    "                        print('cant read',foldername +'/'+filename)\n",
    "                        continue\n",
    "                    read_file_count +=1\n",
    "                    #print(content)\n",
    "                    doc_terms = word_tokenize(content)\n",
    "                    #print(doc_terms)\n",
    "                    stemmed_terms = set([ps.stem(term) for term in doc_terms])\n",
    "                    #doc_term_dict[foldername+'/'+filename] = set(stemmed_terms)\n",
    "                    for term in stemmed_terms:\n",
    "                        self.vocab.add_term(term)\n",
    "                        if term in idf:\n",
    "                            idf[term] +=1\n",
    "                        else:\n",
    "                            idf[term] = 1\n",
    "                    #TVocab.add_term(stemmed_terms[0])\n",
    "                    #print(stemmed_terms)\n",
    "                if file_count>=limit_file_read_to:\n",
    "                    break\n",
    "            if file_count>=limit_file_read_to:\n",
    "                break\n",
    "        D = file_count\n",
    "        for term in idf:\n",
    "            idf[term] = np.log(1 +D/idf[term])\n",
    "        #print(file_count)\n",
    "        self.file_count = file_count\n",
    "        return idf\n",
    "    \n",
    "    def make_doc_vectors(self):\n",
    "        limit_file_read_to = self.limit_file_read_to\n",
    "        coll_dir = self.coll_dir\n",
    "        docs_list = []\n",
    "        tf = {}\n",
    "        idf = self.gen_vocab()\n",
    "        n = self.vocab.vocab_length\n",
    "        print('Creating vector for docs')\n",
    "        ps = PorterStemmer()\n",
    "        file_count = 0\n",
    "        read_file_count = 0\n",
    "        for foldername in os.listdir(coll_dir):\n",
    "            print('For Folder:', foldername)\n",
    "            path_to_file = os.path.join(coll_dir, foldername)\n",
    "            for filename in os.listdir(path_to_file):\n",
    "                file_count+=1\n",
    "                #print('---------------------For File:', filename)\n",
    "                #print('file:', foldername+'/'+filename,end = ' ')\n",
    "                docs_list.append(foldername+'/'+filename)\n",
    "                with open(os.path.join(path_to_file, filename), 'r', encoding= 'latin') as f:\n",
    "                    content = None\n",
    "                    try:\n",
    "                        content = f.read()\n",
    "                    except:\n",
    "                        print('cant read',foldername +'/'+filename)\n",
    "                        continue\n",
    "                    read_file_count +=1\n",
    "                    \n",
    "                    #tokenize and stem\n",
    "                    doc_terms = word_tokenize(content)\n",
    "                    #if len(doc_terms) < 1:\n",
    "                    #    continue\n",
    "                    stemmed_terms = [ps.stem(term) for term in doc_terms]\n",
    "                    \n",
    "                    #make tf vector for docs\n",
    "                    doc_v = np.zeros(n)\n",
    "                    for term in stemmed_terms:\n",
    "                        doc_v[self.vocab.to_index(term)] += 1\n",
    "                    doc_v = np.ma.log(doc_v)\n",
    "                    tf[foldername+'/'+filename] = 1 + doc_v.filled(0)\n",
    "                    \n",
    "                    #include idf part in the vector\n",
    "                    for term_index in range(self.vocab.vocab_length):\n",
    "                        term = self.vocab.to_term(term_index)\n",
    "                        tf[foldername+'/'+filename][term_index] *= idf[term]\n",
    "                    \n",
    "                if file_count>=limit_file_read_to:\n",
    "                    break\n",
    "            if file_count>=limit_file_read_to:\n",
    "                break\n",
    "        self.docs_list = docs_list\n",
    "        print('Files Count:',file_count)\n",
    "        print('Files Read :',read_file_count)\n",
    "        return tf\n",
    "        \n",
    "    def jaccard_sim(self, file_path = None):\n",
    "        doc_term_dict = self.generate_term_set()\n",
    "        if file_path is None:\n",
    "            file_path = self.op_file\n",
    "        self.clear_file(file_path)\n",
    "        n = len(doc_term_dict)\n",
    "        jacob_mat = np.zeros((n,n))\n",
    "        for i, itr_i in zip(doc_term_dict, range(n)):\n",
    "            for j, itr_j in zip(doc_term_dict, range(n)):\n",
    "                if itr_j <= itr_i:\n",
    "                    continue\n",
    "                term_dic_i = doc_term_dict[i]\n",
    "                term_dic_j = doc_term_dict[j]\n",
    "                if len(term_dic_i)>0 or len(term_dic_j)>0:\n",
    "                    nr = len(term_dic_i & term_dic_j)\n",
    "                    dr = len(term_dic_i | term_dic_j)\n",
    "                    jacob_mat[itr_i, itr_j] = nr/dr\n",
    "                    jacob_mat[itr_j, itr_i] = nr/dr\n",
    "                    if jacob_mat[itr_i, itr_j] != 0:\n",
    "                        self.write_to_file(i, j, jacob_mat[itr_i, itr_j], file_path)\n",
    "        print(jacob_mat)\n",
    "        return jacob_mat\n",
    "    \n",
    "    def tf_idf_sim(self, file_path = None):\n",
    "        doc_vectors = self.make_doc_vectors()\n",
    "        n = self.vocab.vocab_length\n",
    "        m = self.file_count\n",
    "        if file_path is None:\n",
    "            file_path = self.op_file\n",
    "        self.clear_file(file_path)\n",
    "        #n = self.file_count\n",
    "        print('file count:', m)\n",
    "        sim_mat = np.zeros((m,m))\n",
    "        #for d1, i in zip(doc_vectors, range(m)):\n",
    "        #    for d2, j in zip(doc_vectors, range(m)):\n",
    "        for i in range(m):\n",
    "            for j in range(i+1,m):\n",
    "                d1 = self.docs_list_list[i]\n",
    "                d2 = self.docs_list[j]\n",
    "                #if j <= i:\n",
    "                #    continue\n",
    "                sim = self.cosine_sim(doc_vectors[d1], doc_vectors[d2])\n",
    "                sim_mat[i,j] = sim\n",
    "                sim_mat[j,i] = sim\n",
    "                if sim > 0:\n",
    "                    self.write_to_file(d1, d2, sim, file_path)\n",
    "        print(sim_mat)\n",
    "        return sim_mat\n",
    "    \n",
    "    def show_graph(self, adj, scores, reduce_width = None):\n",
    "        adj_cpy = np.array(adj)\n",
    "        if reduce_width is not None:\n",
    "            for i in range(adj_cpy.shape[0]):\n",
    "                for j in range(adj_cpy.shape[1]):\n",
    "                    if adj_cpy[i,j] >0:\n",
    "                        adj_cpy[i,j] = reduce_width + np.log(adj[i,j])\n",
    "        \n",
    "        image = svg_graph(\n",
    "            csr_matrix(adj),\n",
    "            scores=scores,\n",
    "            names = self.docs_list)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77bdd57-10df-4a78-af30-fb3a50c29735",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sim = genSimGraph(coll_dir, 'sim_op.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9fc910-3579-4518-8c19-d0032e1c2dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Term set for docs\n",
      "For Folder: sci.space\n",
      "For Folder: talk.politics.mideast\n",
      "For Folder: talk.religion.misc\n",
      "For Folder: comp.os.ms-windows.misc\n",
      "For Folder: sci.med\n",
      "For Folder: rec.sport.hockey\n",
      "For Folder: sci.crypt\n",
      "For Folder: talk.politics.guns\n",
      "For Folder: rec.motorcycles\n",
      "For Folder: comp.graphics\n",
      "For Folder: soc.religion.christian\n",
      "For Folder: comp.sys.ibm.pc.hardware\n",
      "For Folder: misc.forsale\n",
      "For Folder: rec.sport.baseball\n",
      "For Folder: comp.windows.x\n",
      "For Folder: alt.atheism\n",
      "For Folder: rec.autos\n",
      "For Folder: talk.politics.misc\n",
      "For Folder: sci.electronics\n",
      "For Folder: comp.sys.mac.hardware\n",
      "File count: 7532\n",
      "Read File Count: 7532\n",
      "[[0.         0.20178042 0.18181818 ... 0.18302387 0.12080537 0.09056604]\n",
      " [0.20178042 0.         0.17567568 ... 0.15506329 0.12444444 0.10638298]\n",
      " [0.18181818 0.17567568 0.         ... 0.19325153 0.12601626 0.08920188]\n",
      " ...\n",
      " [0.18302387 0.15506329 0.19325153 ... 0.         0.1221374  0.09210526]\n",
      " [0.12080537 0.12444444 0.12601626 ... 0.1221374  0.         0.14166667]\n",
      " [0.09056604 0.10638298 0.08920188 ... 0.09210526 0.14166667 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "jacob_sim_mat = g_sim.jaccard_sim(file_path='jacob_sim_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66ca3321-d686-4499-946d-7c7886b7e113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores-\n",
      "\t: [0.00014609 0.00014101 0.0001434  ... 0.00014178 0.00013563 0.00011892]\n"
     ]
    }
   ],
   "source": [
    "pagerank1 = PageRank(damping_factor=0.85)\n",
    "scores1 = pagerank1.fit_transform(jacob_sim_mat)\n",
    "print('scores-\\n\\t:',scores1)\n",
    "#img = g_sim.show_graph(np.ones_like(jacob_sim_mat), scores1,1)\n",
    "#SVG(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba27c6e2-0d64-4056-871a-bed946aa1fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vocab\n",
      "For Folder: sci.space\n",
      "For Folder: talk.politics.mideast\n",
      "For Folder: talk.religion.misc\n",
      "For Folder: comp.os.ms-windows.misc\n",
      "For Folder: sci.med\n",
      "For Folder: rec.sport.hockey\n",
      "For Folder: sci.crypt\n",
      "For Folder: talk.politics.guns\n",
      "For Folder: rec.motorcycles\n",
      "For Folder: comp.graphics\n",
      "For Folder: soc.religion.christian\n",
      "For Folder: comp.sys.ibm.pc.hardware\n",
      "For Folder: misc.forsale\n",
      "For Folder: rec.sport.baseball\n",
      "For Folder: comp.windows.x\n",
      "For Folder: alt.atheism\n",
      "For Folder: rec.autos\n",
      "For Folder: talk.politics.misc\n",
      "For Folder: sci.electronics\n",
      "For Folder: comp.sys.mac.hardware\n",
      "Creating vector for docs\n",
      "For Folder: sci.space\n",
      "For Folder: talk.politics.mideast\n",
      "For Folder: talk.religion.misc\n",
      "For Folder: comp.os.ms-windows.misc\n",
      "For Folder: sci.med\n",
      "For Folder: rec.sport.hockey\n",
      "For Folder: sci.crypt\n",
      "For Folder: talk.politics.guns\n",
      "For Folder: rec.motorcycles\n",
      "For Folder: comp.graphics\n",
      "For Folder: soc.religion.christian\n",
      "For Folder: comp.sys.ibm.pc.hardware\n",
      "For Folder: misc.forsale\n",
      "For Folder: rec.sport.baseball\n",
      "For Folder: comp.windows.x\n",
      "For Folder: alt.atheism\n",
      "For Folder: rec.autos\n",
      "For Folder: talk.politics.misc\n",
      "For Folder: sci.electronics\n",
      "For Folder: comp.sys.mac.hardware\n",
      "Files Count: 7532\n",
      "Files Read : 7532\n",
      "file count: 7532\n",
      "[[0.         0.99994755 0.99991074 ... 0.99994552 0.99994613 0.99995112]\n",
      " [0.99994755 0.         0.99993029 ... 0.99995993 0.99996412 0.99996877]\n",
      " [0.99991074 0.99993029 0.         ... 0.99992303 0.99992521 0.99992886]\n",
      " ...\n",
      " [0.99994552 0.99995993 0.99992303 ... 0.         0.99996087 0.99996552]\n",
      " [0.99994613 0.99996412 0.99992521 ... 0.99996087 0.         0.9999726 ]\n",
      " [0.99995112 0.99996877 0.99992886 ... 0.99996552 0.9999726  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "ti_sim_mat = g_sim.tf_idf_sim(file_path='tf_idf_sim_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd4ea550-b3c9-479c-bfde-ba2229381280",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores-\n",
      "\t: [0.00013277 0.00013277 0.00013277 ... 0.00013277 0.00013277 0.00013277]\n"
     ]
    }
   ],
   "source": [
    "pagerank2 = PageRank(damping_factor=0.85)\n",
    "scores2 = pagerank2.fit_transform(ti_sim_mat)\n",
    "print('scores-\\n\\t:',scores2)\n",
    "#img = g_sim.show_graph(ti_sim_mat, np.log(scores2),reduce_width=1)\n",
    "#SVG(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37b41bd3-d6ed-4a0e-8ba2-ca8fb634b46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c6760a1-c501-4b4b-a81c-173e216073b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.os.ms-windows.misc/10140' 'comp.windows.x/68012' 'sci.space/61435'\n",
      " 'comp.graphics/38851' 'comp.windows.x/67988' 'comp.windows.x/67462'\n",
      " 'comp.windows.x/67882' 'talk.religion.misc/84286' 'comp.windows.x/67987'\n",
      " 'talk.politics.mideast/76479' 'comp.graphics/38853' 'comp.graphics/39078'\n",
      " 'comp.graphics/39638' 'sci.med/59283' 'comp.sys.mac.hardware/52004'\n",
      " 'comp.graphics/38852' 'talk.politics.mideast/77257' 'sci.med/59285'\n",
      " 'comp.graphics/38778' 'sci.space/61253']\n",
      "[0.00013139 0.00013243 0.00013244 0.00013245 0.00013246 0.00013248\n",
      " 0.00013248 0.00013251 0.00013251 0.00013252 0.00013252 0.00013253\n",
      " 0.00013253 0.00013254 0.00013256 0.00013257 0.00013258 0.00013259\n",
      " 0.00013259 0.0001326 ]\n"
     ]
    }
   ],
   "source": [
    "top_20 = np.argsort(scores2)[:20]\n",
    "t2 = np.array(g_sim.docs_list)[top_20]\n",
    "print(t2)\n",
    "print(scores2[top_20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c41b069-4775-46d2-9ae6-37c9c5acb559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.os.ms-windows.misc/10140' 'comp.windows.x/67988'\n",
      " 'comp.windows.x/67987' 'rec.sport.hockey/54168' 'rec.sport.hockey/54205'\n",
      " 'rec.sport.hockey/54538' 'comp.graphics/38851' 'rec.sport.hockey/54169'\n",
      " 'comp.graphics/38853' 'sci.med/59574' 'rec.sport.hockey/54478'\n",
      " 'comp.graphics/38852' 'sci.space/61435' 'comp.windows.x/68012'\n",
      " 'sci.med/59285' 'rec.sport.hockey/53943' 'alt.atheism/53806'\n",
      " 'rec.sport.hockey/54516' 'comp.windows.x/67882'\n",
      " 'rec.sport.baseball/105108']\n",
      "[2.26723099e-05 2.49488413e-05 2.70599628e-05 3.97940139e-05\n",
      " 4.69058909e-05 4.74716943e-05 4.87818934e-05 5.19611066e-05\n",
      " 5.27712550e-05 5.41476607e-05 5.48563184e-05 5.51077606e-05\n",
      " 5.64311939e-05 5.71489272e-05 5.78474990e-05 5.83283428e-05\n",
      " 5.93790103e-05 5.99703584e-05 6.02264880e-05 6.05336942e-05]\n"
     ]
    }
   ],
   "source": [
    "top_20 = np.argsort(scores1)[:20]\n",
    "t1 = np.array(g_sim.docs_list)[top_20]\n",
    "print(t1)\n",
    "print(scores1[top_20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "681a24be-ce6d-4dc8-90ef-96ef0408b0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comp.graphics/38851',\n",
       " 'comp.graphics/38852',\n",
       " 'comp.graphics/38853',\n",
       " 'comp.os.ms-windows.misc/10140',\n",
       " 'comp.windows.x/67882',\n",
       " 'comp.windows.x/67987',\n",
       " 'comp.windows.x/67988',\n",
       " 'comp.windows.x/68012',\n",
       " 'sci.med/59285',\n",
       " 'sci.space/61435'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(t1) & set(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b074b-3b21-4b07-ace2-1cb3286cfe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e4e27-aaee-4446-a807-0b3bd6414468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a97d98-3411-4bbe-81ae-c1763987097f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "67af4af3-7124-4b35-b22b-9c25d50e1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.array([list(g_sim.doc_term_dict.keys()),(range(len(g_sim.doc_term_dict.keys())))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "62c56f89-a192-4753-a0ef-846184cace19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sci.space/61444' 'sci.space/61440' 'sci.space/61396' 'sci.space/61363'\n",
      "  'sci.space/61321' 'sci.space/61414' 'sci.space/62114']\n",
      " ['0' '1' '2' '3' '4' '5' '6']] (2, 7)\n"
     ]
    }
   ],
   "source": [
    "print(positions, positions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8eb0d215-2702-4f30-b24a-27c42bb19a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14161755 0.14316572 0.14145637 0.14360726 0.14280346 0.14374115\n",
      " 0.14360849]\n"
     ]
    }
   ],
   "source": [
    "pagerank1 = PageRank(damping_factor=0.85)\n",
    "scores1 = pagerank1.fit_transform(ti_sim_mat)\n",
    "print(scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9f6b0e8d-8222-48a5-87ea-12f2c31a3156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15653331 0.15104661 0.15052934 0.16016858 0.11359918 0.14485192\n",
      " 0.12327105]\n"
     ]
    }
   ],
   "source": [
    "pagerank2 = PageRank(damping_factor=0.85)\n",
    "scores2 = pagerank2.fit_transform(jacob_sim_mat)\n",
    "print(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a6cec0e1-2a63-4909-b3fb-05a92e82a803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12563023 0.14717404 0.12339306 0.15329984 0.14205529 0.15515217\n",
      " 0.15329537]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"620.0\" height=\"340\">\n",
       "<path stroke-width=\"7.942196005482167\" stroke=\"gray\" d=\"M 238 320 41 240\"/>\n",
       "<path stroke-width=\"19.067136957237583\" stroke=\"gray\" d=\"M 395 213 20 108\"/>\n",
       "<path stroke-width=\"4.5718726493363\" stroke=\"gray\" d=\"M 182 20 238 320\"/>\n",
       "<path stroke-width=\"13.055728232507658\" stroke=\"gray\" d=\"M 182 20 41 240\"/>\n",
       "<path stroke-width=\"4.176749860666911\" stroke=\"gray\" d=\"M 182 20 420 66\"/>\n",
       "<path stroke-width=\"15.323502295398063\" stroke=\"gray\" d=\"M 182 20 395 213\"/>\n",
       "<path stroke-width=\"16.536358574444943\" stroke=\"gray\" d=\"M 182 20 222 157\"/>\n",
       "<path stroke-width=\"16.920940258984437\" stroke=\"gray\" d=\"M 182 20 20 108\"/>\n",
       "<path stroke-width=\"10.777686614604612\" stroke=\"gray\" d=\"M 222 157 238 320\"/>\n",
       "<path stroke-width=\"17.352130694167606\" stroke=\"gray\" d=\"M 222 157 41 240\"/>\n",
       "<path stroke-width=\"8.58756300885523\" stroke=\"gray\" d=\"M 222 157 420 66\"/>\n",
       "<path stroke-width=\"19.975507320857222\" stroke=\"gray\" d=\"M 222 157 395 213\"/>\n",
       "<path stroke-width=\"16.536358574444943\" stroke=\"gray\" d=\"M 222 157 182 20\"/>\n",
       "<path stroke-width=\"20.0\" stroke=\"gray\" d=\"M 222 157 20 108\"/>\n",
       "<path stroke-width=\"8.464606079559683\" stroke=\"gray\" d=\"M 20 108 238 320\"/>\n",
       "<path stroke-width=\"16.82249994265326\" stroke=\"gray\" d=\"M 20 108 41 240\"/>\n",
       "<path stroke-width=\"8.75451930795174\" stroke=\"gray\" d=\"M 20 108 420 66\"/>\n",
       "<path stroke-width=\"19.067136957237583\" stroke=\"gray\" d=\"M 20 108 395 213\"/>\n",
       "<path stroke-width=\"19.975507320857222\" stroke=\"gray\" d=\"M 395 213 222 157\"/>\n",
       "<path stroke-width=\"15.323502295398063\" stroke=\"gray\" d=\"M 395 213 182 20\"/>\n",
       "<path stroke-width=\"8.872616436428372\" stroke=\"gray\" d=\"M 395 213 420 66\"/>\n",
       "<path stroke-width=\"17.181753198861113\" stroke=\"gray\" d=\"M 395 213 41 240\"/>\n",
       "<path stroke-width=\"0.5\" stroke=\"gray\" d=\"M 238 320 420 66\"/>\n",
       "<path stroke-width=\"9.595517300123532\" stroke=\"gray\" d=\"M 238 320 395 213\"/>\n",
       "<path stroke-width=\"4.5718726493363\" stroke=\"gray\" d=\"M 238 320 182 20\"/>\n",
       "<path stroke-width=\"10.777686614604612\" stroke=\"gray\" d=\"M 238 320 222 157\"/>\n",
       "<path stroke-width=\"8.464606079559683\" stroke=\"gray\" d=\"M 238 320 20 108\"/>\n",
       "<path stroke-width=\"7.942196005482167\" stroke=\"gray\" d=\"M 41 240 238 320\"/>\n",
       "<path stroke-width=\"7.034911652505388\" stroke=\"gray\" d=\"M 41 240 420 66\"/>\n",
       "<path stroke-width=\"17.181753198861113\" stroke=\"gray\" d=\"M 41 240 395 213\"/>\n",
       "<path stroke-width=\"16.920940258984437\" stroke=\"gray\" d=\"M 20 108 182 20\"/>\n",
       "<path stroke-width=\"13.055728232507658\" stroke=\"gray\" d=\"M 41 240 182 20\"/>\n",
       "<path stroke-width=\"16.82249994265326\" stroke=\"gray\" d=\"M 41 240 20 108\"/>\n",
       "<path stroke-width=\"0.5\" stroke=\"gray\" d=\"M 420 66 238 320\"/>\n",
       "<path stroke-width=\"7.034911652505388\" stroke=\"gray\" d=\"M 420 66 41 240\"/>\n",
       "<path stroke-width=\"8.872616436428372\" stroke=\"gray\" d=\"M 420 66 395 213\"/>\n",
       "<path stroke-width=\"4.176749860666911\" stroke=\"gray\" d=\"M 420 66 182 20\"/>\n",
       "<path stroke-width=\"8.58756300885523\" stroke=\"gray\" d=\"M 420 66 222 157\"/>\n",
       "<path stroke-width=\"8.75451930795174\" stroke=\"gray\" d=\"M 420 66 20 108\"/>\n",
       "<path stroke-width=\"9.595517300123532\" stroke=\"gray\" d=\"M 395 213 238 320\"/>\n",
       "<path stroke-width=\"17.352130694167606\" stroke=\"gray\" d=\"M 41 240 222 157\"/>\n",
       "<path stroke-width=\"20.0\" stroke=\"gray\" d=\"M 20 108 222 157\"/>\n",
       "<circle cx=\"238\" cy=\"320\" r=\"7.0\" style=\"fill:rgb(80, 107, 218);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"41\" cy=\"240\" r=\"7.0\" style=\"fill:rgb(244, 154, 123);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"420\" cy=\"66\" r=\"7.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"395\" cy=\"213\" r=\"7.0\" style=\"fill:rgb(201, 59, 55);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"182\" cy=\"20\" r=\"7.0\" style=\"fill:rgb(239, 206, 188);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"222\" cy=\"157\" r=\"7.0\" style=\"fill:rgb(179, 3, 38);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"20\" cy=\"108\" r=\"7.0\" style=\"fill:rgb(201, 59, 55);stroke:black;stroke-width:1.0\"/>\n",
       "<text text-anchor=\"start\" x=\"248\" y=\"320\" font-size=\"12\">sci.space/61444</text><text text-anchor=\"start\" x=\"51\" y=\"240\" font-size=\"12\">sci.space/61440</text><text text-anchor=\"start\" x=\"430\" y=\"66\" font-size=\"12\">sci.space/61396</text><text text-anchor=\"start\" x=\"405\" y=\"213\" font-size=\"12\">sci.space/61363</text><text text-anchor=\"start\" x=\"192\" y=\"20\" font-size=\"12\">sci.space/61321</text><text text-anchor=\"start\" x=\"232\" y=\"157\" font-size=\"12\">sci.space/61414</text><text text-anchor=\"start\" x=\"30\" y=\"108\" font-size=\"12\">sci.space/62114</text></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "ti_sim_mat_cpy = np.zeros_like(ti_sim_mat)\n",
    "for i in range(ti_sim_mat.shape[0]):\n",
    "    for j in range(ti_sim_mat.shape[1]):\n",
    "        if ti_sim_mat[i,j] >0:\n",
    "            ti_sim_mat_cpy[i,j] = 0.1+ np.log(ti_sim_mat[i,j])\n",
    "pr = PageRank()\n",
    "sc = pr.fit_transform(ti_sim_mat_cpy)\n",
    "print(sc)\n",
    "\n",
    "image = svg_graph(csr_matrix(ti_sim_mat_cpy), scores=np.log2(scores1), names = list(g_sim.doc_term_dict.keys()))\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1f8b072e-e58f-4dd6-bdfd-3c232bea3340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"440\" height=\"340\">\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 62 77 62 77\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 307 320 20 203\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 307 320 390 88\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 119 313 62 77\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 119 313 420 216\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 119 313 230 20\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 119 313 307 320\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 119 313 119 313\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 119 313 20 203\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 119 313 390 88\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 20 203 62 77\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 20 203 420 216\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 20 203 230 20\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 20 203 307 320\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 20 203 119 313\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 20 203 20 203\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 20 203 390 88\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 390 88 62 77\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 390 88 420 216\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 390 88 230 20\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 390 88 307 320\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 390 88 119 313\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 307 320 119 313\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 390 88 20 203\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 307 320 307 320\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 307 320 420 216\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 62 77 420 216\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 62 77 230 20\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 62 77 307 320\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 62 77 119 313\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 62 77 20 203\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 62 77 390 88\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 420 216 62 77\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 420 216 420 216\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 420 216 230 20\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 420 216 307 320\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 420 216 119 313\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 420 216 20 203\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 420 216 390 88\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 230 20 62 77\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 230 20 420 216\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 230 20 230 20\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 230 20 307 320\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 230 20 119 313\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 230 20 20 203\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 230 20 390 88\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 307 320 62 77\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 307 320 230 20\"/>\n",
       "<path stroke-width=\"1.0\" stroke=\"black\" d=\"M 390 88 390 88\"/>\n",
       "<circle cx=\"62\" cy=\"77\" r=\"7.0\" style=\"fill:rgb(80, 107, 218);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"420\" cy=\"216\" r=\"7.0\" style=\"fill:rgb(244, 154, 123);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"230\" cy=\"20\" r=\"7.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"307\" cy=\"320\" r=\"7.0\" style=\"fill:rgb(201, 59, 55);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"119\" cy=\"313\" r=\"7.0\" style=\"fill:rgb(239, 206, 188);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"20\" cy=\"203\" r=\"7.0\" style=\"fill:rgb(179, 3, 38);stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"390\" cy=\"88\" r=\"7.0\" style=\"fill:rgb(201, 59, 55);stroke:black;stroke-width:1.0\"/>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = svg_graph(csr_matrix(np.ones_like(ti_sim_mat)), scores=np.log2(scores))\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1e78996c-f93a-458d-9c92-f450d7e39cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sknetwork.data import karate_club\n",
    "graph = karate_club(metadata=True)\n",
    "adjacency = graph.adjacency\n",
    "position = graph.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1e5a40f8-ebcd-47ba-808c-75bd32ea4df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 34)\n",
      "[[False  True  True ...  True False False]\n",
      " [ True False  True ... False False False]\n",
      " [ True  True False ... False  True False]\n",
      " ...\n",
      " [ True False False ... False  True  True]\n",
      " [False False  True ...  True False  True]\n",
      " [False False False ...  True  True False]]\n"
     ]
    }
   ],
   "source": [
    "print(adjacency.shape)\n",
    "# for i in range(34):\n",
    "#     for j in range(34):\n",
    "#         print(i,j, end = ' ')\n",
    "#         print(adjacency[i,j])\n",
    "print(adjacency.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "afa6fff8-e368-4fbe-a56b-f4b993123954",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04 -0.33]\n",
      " [ 0.24 -0.15]\n",
      " [ 0.01 -0.01]\n",
      " [ 0.13 -0.28]\n",
      " [ 0.02 -0.64]\n",
      " [-0.08 -0.75]\n",
      " [ 0.04 -0.76]\n",
      " [ 0.21 -0.25]\n",
      " [ 0.08  0.09]\n",
      " [-0.11  0.23]\n",
      " [-0.13 -0.62]\n",
      " [-0.28 -0.4 ]\n",
      " [ 0.2  -0.53]\n",
      " [ 0.08 -0.07]\n",
      " [ 0.23  0.55]\n",
      " [ 0.06  0.64]\n",
      " [-0.06 -1.  ]\n",
      " [ 0.32 -0.42]\n",
      " [ 0.15  0.6 ]\n",
      " [ 0.19 -0.01]\n",
      " [ 0.27  0.45]\n",
      " [ 0.39 -0.34]\n",
      " [-0.04  0.61]\n",
      " [-0.26  0.41]\n",
      " [-0.51  0.14]\n",
      " [-0.49  0.28]\n",
      " [-0.19  0.68]\n",
      " [-0.28  0.21]\n",
      " [-0.11  0.12]\n",
      " [-0.17  0.54]\n",
      " [ 0.22  0.19]\n",
      " [-0.21  0.09]\n",
      " [ 0.03  0.38]\n",
      " [ 0.    0.33]]\n"
     ]
    }
   ],
   "source": [
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6117cb63-84d9-4231-a225-e63b6ab87d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
